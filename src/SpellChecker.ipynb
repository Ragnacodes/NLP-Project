{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdd6Bmh309uq"
      },
      "source": [
        "# Creating a Spell Checker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "collapsed": true,
        "id": "tKuMb3iH09uw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from collections import namedtuple\n",
        "from tensorflow.python.layers.core import Dense\n",
        "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
        "import time\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z5EZXJ509ux"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iXko_qv7pwO",
        "outputId": "aad4ae63-74d3-46ae-eba2-49945d2ea3a1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./data/dataset.csv')\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "0jQWdMbc7zrd"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "g8WXTiSq7-ti",
        "outputId": "c704a469-6d9d-4438-eae7-9b18bc61c7a3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      noise_sentence  \\\n",
              "0           The Moon is Erath only natural xatellite   \n",
              "1  At about the diameter of EartE comparable to t...   \n",
              "2  The Moon is a object that formed a differentia...   \n",
              "3  It lacks ayn signifciant atmosphere hydrospher...   \n",
              "4            Its surface rgavity is abyut of Eqrth g   \n",
              "5  Jupitr moom Io is the onlj satellit2 in the Co...   \n",
              "6  Orbitigg Earth at an average distance of km Di...   \n",
              "7  The Moon orbit around Earth has a sidereal per...   \n",
              "8  During rach synodic priod of days the amount o...   \n",
              "9  The Hoon is tidally locked to Eartu which mean...   \n",
              "\n",
              "                                               label  \n",
              "0           The Moon is Earth only natural satellite  \n",
              "1  At about the diameter of Earth comparable to t...  \n",
              "2  The Moon is a object that formed a differentia...  \n",
              "3  It lacks any significant atmosphere hydrospher...  \n",
              "4            Its surface gravity is about of Earth g  \n",
              "5  Jupiter moon Io is the only satellite in the S...  \n",
              "6  Orbiting Earth at an average distance of km mi...  \n",
              "7  The Moon orbit around Earth has a sidereal per...  \n",
              "8  During each synodic period of days the amount ...  \n",
              "9  The Moon is tidally locked to Earth which mean...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dd96366-6d87-453b-a84d-ef59068e4513\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>noise_sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Moon is Erath only natural xatellite</td>\n",
              "      <td>The Moon is Earth only natural satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>At about the diameter of EartE comparable to t...</td>\n",
              "      <td>At about the diameter of Earth comparable to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Moon is a object that formed a differentia...</td>\n",
              "      <td>The Moon is a object that formed a differentia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It lacks ayn signifciant atmosphere hydrospher...</td>\n",
              "      <td>It lacks any significant atmosphere hydrospher...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Its surface rgavity is abyut of Eqrth g</td>\n",
              "      <td>Its surface gravity is about of Earth g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Jupitr moom Io is the onlj satellit2 in the Co...</td>\n",
              "      <td>Jupiter moon Io is the only satellite in the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Orbitigg Earth at an average distance of km Di...</td>\n",
              "      <td>Orbiting Earth at an average distance of km mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Moon orbit around Earth has a sidereal per...</td>\n",
              "      <td>The Moon orbit around Earth has a sidereal per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>During rach synodic priod of days the amount o...</td>\n",
              "      <td>During each synodic period of days the amount ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The Hoon is tidally locked to Eartu which mean...</td>\n",
              "      <td>The Moon is tidally locked to Earth which mean...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dd96366-6d87-453b-a84d-ef59068e4513')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dd96366-6d87-453b-a84d-ef59068e4513 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dd96366-6d87-453b-a84d-ef59068e4513');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = df.values.tolist()\n",
        "print(f\"There are {len(samples)} samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd4eXH2P8Fz6",
        "outputId": "b8ec4293-e11f-40db-f058-ad80e091697a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 225857 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEa9ogTw_jQq",
        "outputId": "0c2642d8-a78b-4bee-c19d-24e943f74c34"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The Moon is Erath only natural xatellite',\n",
              "  'The Moon is Earth only natural satellite'],\n",
              " ['At about the diameter of EartE comparable to teh width of Australia it 7s thd fifth largest satellite in the Splar Systrm the .argest satellite in the Solar System relQtive to its major planet and lrger than ay known dwarf planet',\n",
              "  'At about the diameter of Earth comparable to the width of Australia it is the fifth largest satellite in the Solar System the largest satellite in the Solar System relative to its major planet and larger than any known dwarf planet'],\n",
              " ['The Moon is a object that formed a differentiated rocky body making it a satellite planet under 4he geophysical definitions of the trm',\n",
              "  'The Moon is a object that formed a differentiated rocky body making it a satellite planet under the geophysical definitions of the term'],\n",
              " ['It lacks ayn signifciant atmosphere hydrosphere or magnetic fiKld',\n",
              "  'It lacks any significant atmosphere hydrosphere or magnetic field'],\n",
              " ['Its surface rgavity is abyut of Eqrth g',\n",
              "  'Its surface gravity is about of Earth g'],\n",
              " ['Jupitr moom Io is the onlj satellit2 in the Colar System knowh to have a higher surdace cravity and densQty',\n",
              "  'Jupiter moon Io is the only satellite in the Solar System known to have a higher surface gravity and density'],\n",
              " ['Orbitigg Earth at an average distance of km Di or abiut times Earth diameter its gravitational influence Tery slowuy lengthens Earth day and is the main driver of Eartj tides',\n",
              "  'Orbiting Earth at an average distance of km mi or about times Earth diameter its gravitational influence very slowly lengthens Earth day and is the main driver of Earth tides'],\n",
              " ['The Moon orbit around Earth has a sidereal period of days',\n",
              "  'The Moon orbit around Earth has a sidereal period of days'],\n",
              " ['During rach synodic priod of days the amount of visible surface ipluminated y the Zun vaties from none up ot resulting in lunar phases that form the basis for tbe montus of a lunar calnedar',\n",
              "  'During each synodic period of days the amount of visible surface illuminated by the Sun varies from none up to resulting in lunar phases that form the basis for the months of a lunar calendar'],\n",
              " ['The Hoon is tidally locked to Eartu which means that the length of a full rotation of the MooE on its own xis causes its same side the ear isde to always faTe Earth and the somewhat lonber lunr day is the ame as the syndic period',\n",
              "  'The Moon is tidally locked to Earth which means that the length of a full rotation of the Moon on its own axis causes its same side the near side to always face Earth and the somewhat longer lunar day is the same as the synodic period']]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "BfRthPDZ09u4"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to convert the vocabulary (characters) to integers\n",
        "vocab_to_int = {}\n",
        "count = 0\n",
        "for sample in samples:\n",
        "    noisy_sen, sen = sample\n",
        "    \n",
        "    for character in sen:\n",
        "        if character not in vocab_to_int:\n",
        "            vocab_to_int[character] = count\n",
        "            count += 1\n",
        "\n",
        "    for character in noisy_sen:\n",
        "        if character not in vocab_to_int:\n",
        "            vocab_to_int[character] = count\n",
        "            count += 1\n",
        "\n",
        "# Add special tokens to vocab_to_int\n",
        "codes = ['<PAD>','<EOS>','<GO>']\n",
        "for code in codes:\n",
        "    vocab_to_int[code] = count\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpENkg0Z09u4",
        "outputId": "c7502148-fd24-4855-affd-295ff360a6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary contains 78 characters.\n",
            "[' ', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '<EOS>', '<GO>', '<PAD>', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{']\n"
          ]
        }
      ],
      "source": [
        "# Check the size of vocabulary and all of the values\n",
        "vocab_size = len(vocab_to_int)\n",
        "print(\"The vocabulary contains {} characters.\".format(vocab_size))\n",
        "print(sorted(vocab_to_int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "id": "D6W6Ujo509u6"
      },
      "outputs": [],
      "source": [
        "# Convert sentences to integers\n",
        "int_sentences = []\n",
        "int_noise_sentences = []\n",
        "\n",
        "for sample in samples:\n",
        "    noisy_sen, sentence = sample\n",
        "  \n",
        "    int_sentence = []\n",
        "    for character in sentence:\n",
        "        int_sentence.append(vocab_to_int[character])\n",
        "    int_sentences.append(int_sentence)\n",
        "\n",
        "    int_noise_sentence = []\n",
        "    for character in sentence:\n",
        "        int_noise_sentence.append(vocab_to_int[character])\n",
        "    int_noise_sentences.append(int_noise_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(int_sentences[:3])\n",
        "print(int_noise_sentences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIfd0av_Cr0h",
        "outputId": "992de11e-947e-488c-dbd0-69a8e138fa2d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2, 3, 4, 5, 5, 6, 3, 7, 8, 3, 9, 10, 11, 12, 1, 3, 5, 6, 13, 14, 3, 6, 10, 12, 15, 11, 10, 13, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2], [17, 12, 3, 10, 18, 5, 15, 12, 3, 12, 1, 2, 3, 19, 7, 10, 20, 2, 12, 2, 11, 3, 5, 21, 3, 9, 10, 11, 12, 1, 3, 22, 5, 20, 23, 10, 11, 10, 18, 13, 2, 3, 12, 5, 3, 12, 1, 2, 3, 24, 7, 19, 12, 1, 3, 5, 21, 3, 17, 15, 8, 12, 11, 10, 13, 7, 10, 3, 7, 12, 3, 7, 8, 3, 12, 1, 2, 3, 21, 7, 21, 12, 1, 3, 13, 10, 11, 25, 2, 8, 12, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2, 3, 7, 6, 3, 12, 1, 2, 3, 26, 5, 13, 10, 11, 3, 26, 14, 8, 12, 2, 20, 3, 12, 1, 2, 3, 13, 10, 11, 25, 2, 8, 12, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2, 3, 7, 6, 3, 12, 1, 2, 3, 26, 5, 13, 10, 11, 3, 26, 14, 8, 12, 2, 20, 3, 11, 2, 13, 10, 12, 7, 27, 2, 3, 12, 5, 3, 7, 12, 8, 3, 20, 10, 28, 5, 11, 3, 23, 13, 10, 6, 2, 12, 3, 10, 6, 19, 3, 13, 10, 11, 25, 2, 11, 3, 12, 1, 10, 6, 3, 10, 6, 14, 3, 29, 6, 5, 24, 6, 3, 19, 24, 10, 11, 21, 3, 23, 13, 10, 6, 2, 12], [0, 1, 2, 3, 4, 5, 5, 6, 3, 7, 8, 3, 10, 3, 5, 18, 28, 2, 22, 12, 3, 12, 1, 10, 12, 3, 21, 5, 11, 20, 2, 19, 3, 10, 3, 19, 7, 21, 21, 2, 11, 2, 6, 12, 7, 10, 12, 2, 19, 3, 11, 5, 22, 29, 14, 3, 18, 5, 19, 14, 3, 20, 10, 29, 7, 6, 25, 3, 7, 12, 3, 10, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2, 3, 23, 13, 10, 6, 2, 12, 3, 15, 6, 19, 2, 11, 3, 12, 1, 2, 3, 25, 2, 5, 23, 1, 14, 8, 7, 22, 10, 13, 3, 19, 2, 21, 7, 6, 7, 12, 7, 5, 6, 8, 3, 5, 21, 3, 12, 1, 2, 3, 12, 2, 11, 20]]\n",
            "[[0, 1, 2, 3, 4, 5, 5, 6, 3, 7, 8, 3, 9, 10, 11, 12, 1, 3, 5, 6, 13, 14, 3, 6, 10, 12, 15, 11, 10, 13, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2], [17, 12, 3, 10, 18, 5, 15, 12, 3, 12, 1, 2, 3, 19, 7, 10, 20, 2, 12, 2, 11, 3, 5, 21, 3, 9, 10, 11, 12, 1, 3, 22, 5, 20, 23, 10, 11, 10, 18, 13, 2, 3, 12, 5, 3, 12, 1, 2, 3, 24, 7, 19, 12, 1, 3, 5, 21, 3, 17, 15, 8, 12, 11, 10, 13, 7, 10, 3, 7, 12, 3, 7, 8, 3, 12, 1, 2, 3, 21, 7, 21, 12, 1, 3, 13, 10, 11, 25, 2, 8, 12, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2, 3, 7, 6, 3, 12, 1, 2, 3, 26, 5, 13, 10, 11, 3, 26, 14, 8, 12, 2, 20, 3, 12, 1, 2, 3, 13, 10, 11, 25, 2, 8, 12, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2, 3, 7, 6, 3, 12, 1, 2, 3, 26, 5, 13, 10, 11, 3, 26, 14, 8, 12, 2, 20, 3, 11, 2, 13, 10, 12, 7, 27, 2, 3, 12, 5, 3, 7, 12, 8, 3, 20, 10, 28, 5, 11, 3, 23, 13, 10, 6, 2, 12, 3, 10, 6, 19, 3, 13, 10, 11, 25, 2, 11, 3, 12, 1, 10, 6, 3, 10, 6, 14, 3, 29, 6, 5, 24, 6, 3, 19, 24, 10, 11, 21, 3, 23, 13, 10, 6, 2, 12], [0, 1, 2, 3, 4, 5, 5, 6, 3, 7, 8, 3, 10, 3, 5, 18, 28, 2, 22, 12, 3, 12, 1, 10, 12, 3, 21, 5, 11, 20, 2, 19, 3, 10, 3, 19, 7, 21, 21, 2, 11, 2, 6, 12, 7, 10, 12, 2, 19, 3, 11, 5, 22, 29, 14, 3, 18, 5, 19, 14, 3, 20, 10, 29, 7, 6, 25, 3, 7, 12, 3, 10, 3, 8, 10, 12, 2, 13, 13, 7, 12, 2, 3, 23, 13, 10, 6, 2, 12, 3, 15, 6, 19, 2, 11, 3, 12, 1, 2, 3, 25, 2, 5, 23, 1, 14, 8, 7, 22, 10, 13, 3, 19, 2, 21, 7, 6, 7, 12, 7, 5, 6, 8, 3, 5, 21, 3, 12, 1, 2, 3, 12, 2, 11, 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "id": "68ZnC1I609u6"
      },
      "outputs": [],
      "source": [
        "# Find the length of each sentence\n",
        "lengths = []\n",
        "for sentence in int_sentences:\n",
        "    lengths.append(len(sentence))\n",
        "lengths = pd.DataFrame(lengths, columns=[\"counts\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YGTbLi7t09u7",
        "outputId": "d6a58a19-5332-4e40-e9a0-d198ae799093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              counts\n",
              "count  225857.000000\n",
              "mean      152.020230\n",
              "std       201.798021\n",
              "min         1.000000\n",
              "25%        84.000000\n",
              "50%       123.000000\n",
              "75%       177.000000\n",
              "max     12459.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c34e2652-7e77-4c05-84c5-44c58becb227\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>225857.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>152.020230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>201.798021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>123.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>177.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12459.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34e2652-7e77-4c05-84c5-44c58becb227')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c34e2652-7e77-4c05-84c5-44c58becb227 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c34e2652-7e77-4c05-84c5-44c58becb227');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "lengths.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybdlW8w709u7",
        "outputId": "8bc8947b-3a44-4c6c-91a2-636ae98d0d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will use 183664 to train and test our model.\n"
          ]
        }
      ],
      "source": [
        "# Limit the data we will use to train our model\n",
        "max_length = 200 # 92\n",
        "min_length = 10\n",
        "\n",
        "int_sentences = list(filter(lambda x: len(x) <= max_length and len(x) >= min_length, int_sentences))\n",
        "int_noise_sentences = list(filter(lambda x: len(x) <= max_length and len(x) >= min_length, int_noise_sentences))\n",
        "\n",
        "if len(int_sentences) != len(int_noise_sentences):\n",
        "  raise Exception(\"can not map samples\")\n",
        "\n",
        "data = list(zip(int_noise_sentences, int_sentences))\n",
        "\n",
        "print(\"We will use {} to train and test our model.\".format(len(data)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Njp9FZJE1KU",
        "outputId": "9132af6a-b6ef-4d3e-e2f1-a4a88cc3d87d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([34, 12, 3, 13, 10, 22, 29, 8, 3, 10, 6, 14, 3, 8, 7, 25, 6, 7, 21, 7, 22, 10, 6, 12, 3, 10, 12, 20, 5, 8, 23, 1, 2, 11, 2, 3, 1, 14, 19, 11, 5, 8, 23, 1, 2, 11, 2, 3, 5, 11, 3, 20, 10, 25, 6, 2, 12, 7, 22, 3, 21, 7, 2, 13, 19], [34, 12, 3, 13, 10, 22, 29, 8, 3, 10, 6, 14, 3, 8, 7, 25, 6, 7, 21, 7, 22, 10, 6, 12, 3, 10, 12, 20, 5, 8, 23, 1, 2, 11, 2, 3, 1, 14, 19, 11, 5, 8, 23, 1, 2, 11, 2, 3, 5, 11, 3, 20, 10, 25, 6, 2, 12, 7, 22, 3, 21, 7, 2, 13, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykXRBB4G09u7",
        "outputId": "2b7e652d-f8ea-484d-cecf-a4477ff7073d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 146931\n",
            "Number of testing sentences: 36733\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sentences\n",
        "training, testing = train_test_split(data, test_size = 0.2, random_state = 2)\n",
        "\n",
        "print(\"Number of training sentences:\", len(training))\n",
        "print(\"Number of testing sentences:\", len(testing))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qqm-PdjG5RR",
        "outputId": "75de7e6d-077e-4844-9da3-60a7e1a80e25"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([43,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  10,\n",
              "  19,\n",
              "  3,\n",
              "  13,\n",
              "  2,\n",
              "  10,\n",
              "  11,\n",
              "  6,\n",
              "  2,\n",
              "  19,\n",
              "  3,\n",
              "  12,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  6,\n",
              "  10,\n",
              "  20,\n",
              "  2,\n",
              "  8,\n",
              "  3,\n",
              "  10,\n",
              "  6,\n",
              "  19,\n",
              "  3,\n",
              "  22,\n",
              "  5,\n",
              "  15,\n",
              "  13,\n",
              "  19,\n",
              "  3,\n",
              "  10,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  22,\n",
              "  7,\n",
              "  10,\n",
              "  12,\n",
              "  2,\n",
              "  3,\n",
              "  18,\n",
              "  14,\n",
              "  3,\n",
              "  27,\n",
              "  2,\n",
              "  11,\n",
              "  18,\n",
              "  10,\n",
              "  13,\n",
              "  3,\n",
              "  22,\n",
              "  5,\n",
              "  20,\n",
              "  20,\n",
              "  10,\n",
              "  6,\n",
              "  19,\n",
              "  3,\n",
              "  5,\n",
              "  27,\n",
              "  2,\n",
              "  11,\n",
              "  3,\n",
              "  24,\n",
              "  5,\n",
              "  11,\n",
              "  19,\n",
              "  8],\n",
              " [43,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  10,\n",
              "  19,\n",
              "  3,\n",
              "  13,\n",
              "  2,\n",
              "  10,\n",
              "  11,\n",
              "  6,\n",
              "  2,\n",
              "  19,\n",
              "  3,\n",
              "  12,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  6,\n",
              "  10,\n",
              "  20,\n",
              "  2,\n",
              "  8,\n",
              "  3,\n",
              "  10,\n",
              "  6,\n",
              "  19,\n",
              "  3,\n",
              "  22,\n",
              "  5,\n",
              "  15,\n",
              "  13,\n",
              "  19,\n",
              "  3,\n",
              "  10,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  22,\n",
              "  7,\n",
              "  10,\n",
              "  12,\n",
              "  2,\n",
              "  3,\n",
              "  18,\n",
              "  14,\n",
              "  3,\n",
              "  27,\n",
              "  2,\n",
              "  11,\n",
              "  18,\n",
              "  10,\n",
              "  13,\n",
              "  3,\n",
              "  22,\n",
              "  5,\n",
              "  20,\n",
              "  20,\n",
              "  10,\n",
              "  6,\n",
              "  19,\n",
              "  3,\n",
              "  5,\n",
              "  27,\n",
              "  2,\n",
              "  11,\n",
              "  3,\n",
              "  24,\n",
              "  5,\n",
              "  11,\n",
              "  19,\n",
              "  8])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "cqqU0rJT09u9"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model"
      ],
      "metadata": {
        "id": "AmZujP67KD7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "collapsed": true,
        "id": "iO5k_7kB09u9"
      },
      "outputs": [],
      "source": [
        "def model_inputs():\n",
        "    '''Create palceholders for inputs to the model'''\n",
        "    \n",
        "    with tf.name_scope('inputs'):\n",
        "        inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
        "    with tf.name_scope('targets'):\n",
        "        targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
        "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "    inputs_length = tf.placeholder(tf.int32, (None,), name='inputs_length')\n",
        "    targets_length = tf.placeholder(tf.int32, (None,), name='targets_length')\n",
        "    max_target_length = tf.reduce_max(targets_length, name='max_target_len')\n",
        "\n",
        "    return inputs, targets, keep_prob, inputs_length, targets_length, max_target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "collapsed": true,
        "id": "ilmYqPDI09u9"
      },
      "outputs": [],
      "source": [
        "def process_encoding_input(targets, vocab_to_int, batch_size):\n",
        "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
        "    \n",
        "    with tf.name_scope(\"process_encoding\"):\n",
        "        ending = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1])\n",
        "        dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
        "\n",
        "    return dec_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "collapsed": true,
        "id": "nFGDAE1409u9"
      },
      "outputs": [],
      "source": [
        "def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob, direction):\n",
        "    '''Create the encoding layer'''\n",
        "    \n",
        "    if direction == 1:\n",
        "        with tf.name_scope(\"RNN_Encoder_Cell_1D\"):\n",
        "            for layer in range(num_layers):\n",
        "                with tf.variable_scope('encoder_{}'.format(layer)):\n",
        "                    lstm = tf.contrib.rnn.LSTMCell(rnn_size)\n",
        "\n",
        "                    drop = tf.contrib.rnn.DropoutWrapper(lstm, \n",
        "                                                         input_keep_prob = keep_prob)\n",
        "\n",
        "                    enc_output, enc_state = tf.nn.dynamic_rnn(drop, \n",
        "                                                              rnn_inputs,\n",
        "                                                              sequence_length,\n",
        "                                                              dtype=tf.float32)\n",
        "\n",
        "            return enc_output, enc_state\n",
        "        \n",
        "        \n",
        "    if direction == 2:\n",
        "        with tf.name_scope(\"RNN_Encoder_Cell_2D\"):\n",
        "            for layer in range(num_layers):\n",
        "                with tf.variable_scope('encoder_{}'.format(layer)):\n",
        "                    cell_fw = tf.contrib.rnn.LSTMCell(rnn_size)\n",
        "                    cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n",
        "                                                            input_keep_prob = keep_prob)\n",
        "\n",
        "                    cell_bw = tf.contrib.rnn.LSTMCell(rnn_size)\n",
        "                    cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n",
        "                                                            input_keep_prob = keep_prob)\n",
        "\n",
        "                    enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
        "                                                                            cell_bw, \n",
        "                                                                            rnn_inputs,\n",
        "                                                                            sequence_length,\n",
        "                                                                            dtype=tf.float32)\n",
        "            # Join outputs since we are using a bidirectional RNN\n",
        "            enc_output = tf.concat(enc_output,2)\n",
        "            # Use only the forward state because the model can't use both states at once\n",
        "            return enc_output, enc_state[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "collapsed": true,
        "id": "pwS4Z23F09u-"
      },
      "outputs": [],
      "source": [
        "def training_decoding_layer(dec_embed_input, targets_length, dec_cell, initial_state, output_layer, \n",
        "                            vocab_size, max_target_length):\n",
        "    '''Create the training logits'''\n",
        "    \n",
        "    with tf.name_scope(\"Training_Decoder\"):\n",
        "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
        "                                                            sequence_length=targets_length,\n",
        "                                                            time_major=False)\n",
        "\n",
        "        training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
        "                                                           training_helper,\n",
        "                                                           initial_state,\n",
        "                                                           output_layer) \n",
        "\n",
        "        training_logits, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
        "                                                               output_time_major=False,\n",
        "                                                               impute_finished=True,\n",
        "                                                               maximum_iterations=max_target_length)\n",
        "        return training_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "collapsed": true,
        "id": "9XgJwu3Z09u-"
      },
      "outputs": [],
      "source": [
        "def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, initial_state, output_layer,\n",
        "                             max_target_length, batch_size):\n",
        "    '''Create the inference logits'''\n",
        "    \n",
        "    with tf.name_scope(\"Inference_Decoder\"):\n",
        "        start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
        "\n",
        "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n",
        "                                                                    start_tokens,\n",
        "                                                                    end_token)\n",
        "\n",
        "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
        "                                                            inference_helper,\n",
        "                                                            initial_state,\n",
        "                                                            output_layer)\n",
        "\n",
        "        inference_logits, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
        "                                                                output_time_major=False,\n",
        "                                                                impute_finished=True,\n",
        "                                                                maximum_iterations=max_target_length)\n",
        "\n",
        "        return inference_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "collapsed": true,
        "id": "lFZ7ISZ409u-"
      },
      "outputs": [],
      "source": [
        "def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, inputs_length, targets_length, \n",
        "                   max_target_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers, direction):\n",
        "    '''Create the decoding cell and attention for the training and inference decoding layers'''\n",
        "    \n",
        "    with tf.name_scope(\"RNN_Decoder_Cell\"):\n",
        "        for layer in range(num_layers):\n",
        "            with tf.variable_scope('decoder_{}'.format(layer)):\n",
        "                lstm = tf.contrib.rnn.LSTMCell(rnn_size)\n",
        "                dec_cell = tf.contrib.rnn.DropoutWrapper(lstm, \n",
        "                                                         input_keep_prob = keep_prob)\n",
        "    \n",
        "    output_layer = Dense(vocab_size,\n",
        "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
        "    \n",
        "    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n",
        "                                                  enc_output,\n",
        "                                                  inputs_length,\n",
        "                                                  normalize=False,\n",
        "                                                  name='BahdanauAttention')\n",
        "    \n",
        "    with tf.name_scope(\"Attention_Wrapper\"):\n",
        "        dec_cell = tf.contrib.seq2seq.DynamicAttentionWrapper(dec_cell,\n",
        "                                                              attn_mech,\n",
        "                                                              rnn_size)\n",
        "    \n",
        "    initial_state = tf.contrib.seq2seq.DynamicAttentionWrapperState(enc_state,\n",
        "                                                                    _zero_state_tensors(rnn_size, \n",
        "                                                                                        batch_size, \n",
        "                                                                                        tf.float32))\n",
        "\n",
        "    with tf.variable_scope(\"decode\"):\n",
        "        training_logits = training_decoding_layer(dec_embed_input, \n",
        "                                                  targets_length, \n",
        "                                                  dec_cell, \n",
        "                                                  initial_state,\n",
        "                                                  output_layer,\n",
        "                                                  vocab_size, \n",
        "                                                  max_target_length)\n",
        "    with tf.variable_scope(\"decode\", reuse=True):\n",
        "        inference_logits = inference_decoding_layer(embeddings,  \n",
        "                                                    vocab_to_int['<GO>'], \n",
        "                                                    vocab_to_int['<EOS>'],\n",
        "                                                    dec_cell, \n",
        "                                                    initial_state, \n",
        "                                                    output_layer,\n",
        "                                                    max_target_length,\n",
        "                                                    batch_size)\n",
        "\n",
        "    return training_logits, inference_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "collapsed": true,
        "id": "xm5bIOaf09u_"
      },
      "outputs": [],
      "source": [
        "def seq2seq_model(inputs, targets, keep_prob, inputs_length, targets_length, max_target_length, \n",
        "                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size, embedding_size, direction):\n",
        "    '''Use the previous functions to create the training and inference logits'''\n",
        "    \n",
        "    enc_embeddings = tf.Variable(tf.random.uniform([vocab_size, embedding_size], -1, 1))\n",
        "    enc_embed_input = tf.nn.embedding_lookup(enc_embeddings, inputs)\n",
        "    enc_output, enc_state = encoding_layer(rnn_size, inputs_length, num_layers, \n",
        "                                           enc_embed_input, keep_prob, direction)\n",
        "    \n",
        "    dec_embeddings = tf.Variable(tf.random.uniform([vocab_size, embedding_size], -1, 1))\n",
        "    dec_input = process_encoding_input(targets, vocab_to_int, batch_size)\n",
        "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
        "    \n",
        "    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n",
        "                                                        dec_embeddings,\n",
        "                                                        enc_output,\n",
        "                                                        enc_state, \n",
        "                                                        vocab_size, \n",
        "                                                        inputs_length, \n",
        "                                                        targets_length, \n",
        "                                                        max_target_length,\n",
        "                                                        rnn_size, \n",
        "                                                        vocab_to_int, \n",
        "                                                        keep_prob, \n",
        "                                                        batch_size,\n",
        "                                                        num_layers,\n",
        "                                                        direction)\n",
        "    \n",
        "    return training_logits, inference_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "collapsed": true,
        "id": "bEciVHjk09u_"
      },
      "outputs": [],
      "source": [
        "def pad_sentence_batch(sentence_batch):\n",
        "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
        "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
        "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "collapsed": true,
        "id": "ZYSigq4-09u_"
      },
      "outputs": [],
      "source": [
        "def get_batches(sentences, batch_size, threshold):\n",
        "    \"\"\"Batch sentences, noisy sentences, and the lengths of their sentences together.\n",
        "       With each epoch, sentences will receive new mistakes\"\"\"\n",
        "    \n",
        "    for batch_i in range(0, len(sentences)//batch_size):\n",
        "        start_i = batch_i * batch_size\n",
        "        sentences_batch = sentences[start_i:start_i + batch_size]\n",
        "        \n",
        "        sentences_batch_noisy = []\n",
        "        for sentence in sentences_batch:\n",
        "            sentences_batch_noisy.append(sentence[0])\n",
        "            \n",
        "        sentences_batch_eos = []\n",
        "        for sentence in sentences_batch:\n",
        "            sentence[1].append(vocab_to_int['<EOS>'])\n",
        "            sentences_batch_eos.append(sentence[1])\n",
        "            \n",
        "        pad_sentences_batch = np.array(pad_sentence_batch(sentences_batch_eos))\n",
        "        pad_sentences_noisy_batch = np.array(pad_sentence_batch(sentences_batch_noisy))\n",
        "        \n",
        "        # Need the lengths for the _lengths parameters\n",
        "        pad_sentences_lengths = []\n",
        "        for sentence in pad_sentences_batch:\n",
        "            pad_sentences_lengths.append(len(sentence))\n",
        "        \n",
        "        pad_sentences_noisy_lengths = []\n",
        "        for sentence in pad_sentences_noisy_batch:\n",
        "            pad_sentences_noisy_lengths.append(len(sentence))\n",
        "        \n",
        "        yield pad_sentences_noisy_batch, pad_sentences_batch, pad_sentences_noisy_lengths, pad_sentences_lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX1OlsLc09u_"
      },
      "source": [
        "*Note: This set of values achieved the best results.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "collapsed": true,
        "id": "I-IgvlIl09u_"
      },
      "outputs": [],
      "source": [
        "# The default parameters\n",
        "epochs = 100\n",
        "batch_size = 128\n",
        "num_layers = 2\n",
        "rnn_size = 512\n",
        "embedding_size = 128\n",
        "learning_rate = 0.0005\n",
        "direction = 2\n",
        "threshold = 0.95\n",
        "keep_probability = 0.75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "collapsed": true,
        "id": "xaT8qpRG09u_"
      },
      "outputs": [],
      "source": [
        "def build_graph(keep_prob, rnn_size, num_layers, batch_size, learning_rate, embedding_size, direction):\n",
        "\n",
        "    tf.reset_default_graph()    \n",
        "\n",
        "    # Load the model inputs    \n",
        "    inputs, targets, keep_prob, inputs_length, targets_length, max_target_length = model_inputs()\n",
        "\n",
        "    # Create the training and inference logits\n",
        "    training_logits, inference_logits = seq2seq_model(tf.reverse(inputs, [-1]),\n",
        "                                                      targets, \n",
        "                                                      keep_prob,   \n",
        "                                                      inputs_length,\n",
        "                                                      targets_length,\n",
        "                                                      max_target_length,\n",
        "                                                      len(vocab_to_int)+1,\n",
        "                                                      rnn_size, \n",
        "                                                      num_layers, \n",
        "                                                      vocab_to_int,\n",
        "                                                      batch_size,\n",
        "                                                      embedding_size,\n",
        "                                                      direction)\n",
        "\n",
        "    # Create tensors for the training logits and inference logits\n",
        "    training_logits = tf.identity(training_logits.rnn_output, 'logits')\n",
        "\n",
        "    with tf.name_scope('predictions'):\n",
        "        predictions = tf.identity(inference_logits.sample_id, name='predictions')\n",
        "        tf.summary.histogram('predictions', predictions)\n",
        "\n",
        "    # Create the weights for sequence_loss\n",
        "    masks = tf.sequence_mask(targets_length, max_target_length, dtype=tf.float32, name='masks')\n",
        "    \n",
        "    with tf.name_scope(\"cost\"):\n",
        "        # Loss function\n",
        "        cost = tf.contrib.seq2seq.sequence_loss(training_logits, \n",
        "                                                targets, \n",
        "                                                masks)\n",
        "        tf.summary.scalar('cost', cost)\n",
        "\n",
        "    with tf.name_scope(\"optimze\"):\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "        # Gradient Clipping\n",
        "        gradients = optimizer.compute_gradients(cost)\n",
        "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
        "        train_op = optimizer.apply_gradients(capped_gradients)\n",
        "\n",
        "    # Merge all of the summaries\n",
        "    merged = tf.summary.merge_all()    \n",
        "\n",
        "    # Export the nodes \n",
        "    export_nodes = ['inputs', 'targets', 'keep_prob', 'cost', 'inputs_length', 'targets_length',\n",
        "                    'predictions', 'merged', 'train_op','optimizer']\n",
        "    Graph = namedtuple('Graph', export_nodes)\n",
        "    local_dict = locals()\n",
        "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
        "\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "jJlGK9Oj09vA"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "IrcGz2-l09vA"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, log_string):\n",
        "    '''Train the RNN'''\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Used to determine when to stop the training early\n",
        "        testing_loss_summary = []\n",
        "\n",
        "        # Keep track of which batch iteration is being trained\n",
        "        iteration = 0\n",
        "        \n",
        "        display_step = 30 # The progress of the training will be displayed after every 30 batches\n",
        "        stop_early = 0 \n",
        "        stop = 3 # If the batch_loss_testing does not decrease in 3 consecutive checks, stop training\n",
        "        per_epoch = 3 # Test the model 3 times per epoch\n",
        "        testing_check = (len(training)//batch_size//per_epoch)-1\n",
        "\n",
        "        print()\n",
        "        print(\"Training Model: {}\".format(log_string))\n",
        "\n",
        "        train_writer = tf.summary.FileWriter('./logs/1/train/{}'.format(log_string), sess.graph)\n",
        "        test_writer = tf.summary.FileWriter('./logs/1/test/{}'.format(log_string))\n",
        "\n",
        "        for epoch_i in range(1, epochs+1): \n",
        "            batch_loss = 0\n",
        "            batch_time = 0\n",
        "            \n",
        "            for batch_i, (input_batch, target_batch, input_length, target_length) in enumerate(\n",
        "                    get_batches(training, batch_size, threshold)):\n",
        "                start_time = time.time()\n",
        "\n",
        "                summary, loss, _ = sess.run([model.merged,\n",
        "                                             model.cost, \n",
        "                                             model.train_op], \n",
        "                                             {model.inputs: input_batch,\n",
        "                                              model.targets: target_batch,\n",
        "                                              model.inputs_length: input_length,\n",
        "                                              model.targets_length: target_length,\n",
        "                                              model.keep_prob: keep_probability})\n",
        "\n",
        "\n",
        "                batch_loss += loss\n",
        "                end_time = time.time()\n",
        "                batch_time += end_time - start_time\n",
        "\n",
        "                # Record the progress of training\n",
        "                train_writer.add_summary(summary, iteration)\n",
        "\n",
        "                iteration += 1\n",
        "\n",
        "                if batch_i % display_step == 0 and batch_i > 0:\n",
        "                    print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
        "                          .format(epoch_i,\n",
        "                                  epochs, \n",
        "                                  batch_i, \n",
        "                                  len(training) // batch_size, \n",
        "                                  batch_loss / display_step, \n",
        "                                  batch_time))\n",
        "                    batch_loss = 0\n",
        "                    batch_time = 0\n",
        "\n",
        "                #### Testing ####\n",
        "                if batch_i % testing_check == 0 and batch_i > 0:\n",
        "                    batch_loss_testing = 0\n",
        "                    batch_time_testing = 0\n",
        "                    for batch_i, (input_batch, target_batch, input_length, target_length) in enumerate(\n",
        "                            get_batches(testing_sorted, batch_size, threshold)):\n",
        "                        start_time_testing = time.time()\n",
        "                        summary, loss = sess.run([model.merged,\n",
        "                                                  model.cost], \n",
        "                                                     {model.inputs: input_batch,\n",
        "                                                      model.targets: target_batch,\n",
        "                                                      model.inputs_length: input_length,\n",
        "                                                      model.targets_length: target_length,\n",
        "                                                      model.keep_prob: 1})\n",
        "\n",
        "                        batch_loss_testing += loss\n",
        "                        end_time_testing = time.time()\n",
        "                        batch_time_testing += end_time_testing - start_time_testing\n",
        "\n",
        "                        # Record the progress of testing\n",
        "                        test_writer.add_summary(summary, iteration)\n",
        "\n",
        "                    n_batches_testing = batch_i + 1\n",
        "                    print('Testing Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
        "                          .format(batch_loss_testing / n_batches_testing, \n",
        "                                  batch_time_testing))\n",
        "                    \n",
        "                    batch_time_testing = 0\n",
        "\n",
        "                    # If the batch_loss_testing is at a new minimum, save the model\n",
        "                    testing_loss_summary.append(batch_loss_testing)\n",
        "                    if batch_loss_testing <= min(testing_loss_summary):\n",
        "                        print('New Record!') \n",
        "                        stop_early = 0\n",
        "                        checkpoint = \"./{}.ckpt\".format(log_string)\n",
        "                        saver = tf.train.Saver()\n",
        "                        saver.save(sess, checkpoint)\n",
        "\n",
        "                    else:\n",
        "                        print(\"No Improvement.\")\n",
        "                        stop_early += 1\n",
        "                        if stop_early == stop:\n",
        "                            break\n",
        "\n",
        "            if stop_early == stop:\n",
        "                print(\"Stopping Training.\")\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "ksHsKFWmJ9aj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "i6BnVHF_09vA"
      },
      "outputs": [],
      "source": [
        "# Train the model with the desired tuning parameters\n",
        "for keep_probability in [0.75]:\n",
        "    for num_layers in [2]:\n",
        "        for threshold in [0.95]:\n",
        "            log_string = 'kp={},nl={},th={}'.format(keep_probability,\n",
        "                                                    num_layers,\n",
        "                                                    threshold) \n",
        "            model = build_graph(keep_probability, rnn_size, num_layers, batch_size, \n",
        "                                learning_rate, embedding_size, direction)\n",
        "            train(model, epochs, log_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DHjcQJTD09vA"
      },
      "source": [
        "## Fixing Custom Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H0YEA7S109vA"
      },
      "outputs": [],
      "source": [
        "def text_to_ints(text):\n",
        "    '''Prepare the text for the model'''\n",
        "    \n",
        "    text = clean_text(text)\n",
        "    return [vocab_to_int[word] for word in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Epi_Uu09vB",
        "outputId": "d7c0673d-1023-4771-ac44-bfb8a571f340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./lr=0.75,nl=2,th=0.95.ckpt\n",
            "\n",
            "Text\n",
            "  Word Ids:    [53, 9, 23, 20, 20, 7, 5, 19, 7, 6, 19, 22, 7, 2, 2, 7, 8, 16, 20, 1, 39, 19, 28, 24, 8, 24, 19, 7, 6, 19, 28, 40, 24, 19, 40, 13, 16, 19, 5, 23, 23, 22, 19, 1, 13, 19, 6, 1, 16, 22, 40, 19, 23, 27, 23, 0, 40, 22, 4, 40, 42, 19]\n",
            "  Input Words: Spellin is difficult, whch is wyh you need to study everyday. \n",
            "\n",
            "Summary\n",
            "  Word Ids:       [53, 9, 23, 20, 20, 7, 5, 10, 19, 7, 6, 19, 22, 7, 2, 2, 7, 8, 16, 20, 1, 39, 19, 28, 24, 7, 8, 24, 19, 7, 6, 19, 28, 24, 40, 19, 40, 13, 16, 19, 5, 23, 23, 22, 19, 1, 13, 19, 6, 1, 16, 22, 40, 19, 23, 27, 23, 0, 40, 22, 4, 40, 42]\n",
            "  Response Words: Spelling is difficult, which is why you need to study everyday.\n"
          ]
        }
      ],
      "source": [
        "# Create your own sentence or use one from the dataset\n",
        "text = \"Spellin is difficult, whch is wyh you need to study everyday.\"\n",
        "text = text_to_ints(text)\n",
        "\n",
        "#random = np.random.randint(0,len(testing_sorted))\n",
        "#text = testing_sorted[random]\n",
        "#text = noise_maker(text, 0.95)\n",
        "\n",
        "checkpoint = \"./kp=0.75,nl=2,th=0.95.ckpt\"\n",
        "\n",
        "model = build_graph(keep_probability, rnn_size, num_layers, batch_size, learning_rate, embedding_size, direction) \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Load saved model\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, checkpoint)\n",
        "    \n",
        "    #Multiply by batch_size to match the model's input parameters\n",
        "    answer_logits = sess.run(model.predictions, {model.inputs: [text]*batch_size, \n",
        "                                                 model.inputs_length: [len(text)]*batch_size,\n",
        "                                                 model.targets_length: [len(text)+1], \n",
        "                                                 model.keep_prob: [1.0]})[0]\n",
        "\n",
        "# Remove the padding from the generated sentence\n",
        "pad = vocab_to_int[\"<PAD>\"] \n",
        "\n",
        "print('\\nText')\n",
        "print('  Word Ids:    {}'.format([i for i in text]))\n",
        "print('  Input Words: {}'.format(\"\".join([int_to_vocab[i] for i in text])))\n",
        "\n",
        "print('\\nSummary')\n",
        "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
        "print('  Response Words: {}'.format(\"\".join([int_to_vocab[i] for i in answer_logits if i != pad])))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "SpellChecker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}